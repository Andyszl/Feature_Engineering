{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>desc</th>\n",
       "      <th>...</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I need to upgra...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-11</td>\n",
       "      <td>Jan-85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-11</td>\n",
       "      <td>Apr-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-11</td>\n",
       "      <td>Nov-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-11</td>\n",
       "      <td>Feb-96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; I plan on combi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-11</td>\n",
       "      <td>Jan-96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_id  loan_amnt        term  loan_status int_rate emp_length  \\\n",
       "0          1       5000   36 months   Fully Paid   10.65%  10+ years   \n",
       "1          2       2500   60 months  Charged Off   15.27%   < 1 year   \n",
       "2          3       2400   36 months   Fully Paid   15.96%  10+ years   \n",
       "3          4      10000   36 months   Fully Paid   13.49%  10+ years   \n",
       "4          5       3000   60 months   Fully Paid   12.69%     1 year   \n",
       "\n",
       "  home_ownership  annual_inc verification_status  \\\n",
       "0           RENT     24000.0            Verified   \n",
       "1           RENT     30000.0     Source Verified   \n",
       "2           RENT     12252.0        Not Verified   \n",
       "3           RENT     49200.0     Source Verified   \n",
       "4           RENT     80000.0     Source Verified   \n",
       "\n",
       "                                                desc  ... delinq_2yrs  \\\n",
       "0    Borrower added on 12/22/11 > I need to upgra...  ...           0   \n",
       "1    Borrower added on 12/22/11 > I plan to use t...  ...           0   \n",
       "2                                                NaN  ...           0   \n",
       "3    Borrower added on 12/21/11 > to pay for prop...  ...           0   \n",
       "4    Borrower added on 12/21/11 > I plan on combi...  ...           0   \n",
       "\n",
       "  inq_last_6mths mths_since_last_delinq mths_since_last_record  open_acc  \\\n",
       "0              1                    NaN                    NaN         3   \n",
       "1              5                    NaN                    NaN         3   \n",
       "2              2                    NaN                    NaN         2   \n",
       "3              1                   35.0                    NaN        10   \n",
       "4              0                   38.0                    NaN        15   \n",
       "\n",
       "   pub_rec  total_acc  pub_rec_bankruptcies  issue_d  earliest_cr_line  \n",
       "0        0          9                   0.0   Dec-11            Jan-85  \n",
       "1        0          4                   0.0   Dec-11            Apr-99  \n",
       "2        0         10                   0.0   Dec-11            Nov-01  \n",
       "3        0         37                   0.0   Dec-11            Feb-96  \n",
       "4        0         38                   0.0   Dec-11            Jan-96  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('application.csv', encoding='ISO-8859-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39785 entries, 0 to 39784\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   member_id               39785 non-null  int64  \n",
      " 1   loan_amnt               39785 non-null  int64  \n",
      " 2   term                    39785 non-null  object \n",
      " 3   loan_status             39785 non-null  object \n",
      " 4   int_rate                39785 non-null  object \n",
      " 5   emp_length              38707 non-null  object \n",
      " 6   home_ownership          39785 non-null  object \n",
      " 7   annual_inc              39785 non-null  float64\n",
      " 8   verification_status     39785 non-null  object \n",
      " 9   desc                    26818 non-null  object \n",
      " 10  purpose                 39785 non-null  object \n",
      " 11  title                   39774 non-null  object \n",
      " 12  zip_code                39785 non-null  object \n",
      " 13  addr_state              39785 non-null  object \n",
      " 14  dti                     39785 non-null  float64\n",
      " 15  delinq_2yrs             39785 non-null  int64  \n",
      " 16  inq_last_6mths          39785 non-null  int64  \n",
      " 17  mths_since_last_delinq  14058 non-null  float64\n",
      " 18  mths_since_last_record  2791 non-null   float64\n",
      " 19  open_acc                39785 non-null  int64  \n",
      " 20  pub_rec                 39785 non-null  int64  \n",
      " 21  total_acc               39785 non-null  int64  \n",
      " 22  pub_rec_bankruptcies    39088 non-null  float64\n",
      " 23  issue_d                 39785 non-null  object \n",
      " 24  earliest_cr_line        39785 non-null  object \n",
      "dtypes: float64(5), int64(7), object(13)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#查看数据\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目标变量处理\n",
    "data['y'] = data['loan_status'].map(lambda x: int(x == 'Charged Off'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 拆分数据\n",
    "def SplitData(df, col, numOfSplit, special_attribute=[]):\n",
    "    '''\n",
    "    :param df: 按照col排序后的数据集\n",
    "    :param col: 待分箱的变量\n",
    "    :param numOfSplit: 切分的组别数\n",
    "    :param special_attribute: 在切分数据集的时候，某些特殊值需要排除在外\n",
    "    :return: 在原数据集上增加一列，把原始细粒度的col重新划分成粗粒度的值，便于分箱中的合并处理\n",
    "    '''\n",
    "    df2 = df.copy()\n",
    "    if special_attribute != []:\n",
    "        df2 = df.loc[~df[col].isin(special_attribute)]\n",
    "    N = df2.shape[0]#总样本数\n",
    "    n = round(N/numOfSplit)#每一层有多少样本\n",
    "    print(n)\n",
    "    splitPointIndex = [i*n for i in range(1,numOfSplit)]\n",
    "    #print(splitPointIndex)\n",
    "    rawValues = sorted(list(df2[col]))#将所有的样本进行排序\n",
    "    splitPoint = [rawValues[i] for i in splitPointIndex]#以样本排序的rank为索引，找到每个临界值的点的数值\n",
    "    splitPoint = sorted(list(set(splitPoint)))\n",
    "    return splitPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. \n",
    "#临界值的选取1\n",
    "def AssignGroup(x, bin):\n",
    "    N = len(bin)\n",
    "    #如果值小于最小的分箱值，则取最小的分箱值\n",
    "    if x<=min(bin):\n",
    "        return min(bin)\n",
    "    # 如果值大于最大的分箱值，则取10e10\n",
    "    elif x>max(bin):\n",
    "        return 10e10\n",
    "    else:\n",
    "        #介于中间的值取又边界值\n",
    "        for i in range(N-1):\n",
    "            if bin[i] < x <= bin[i+1]:\n",
    "                return bin[i+1]\n",
    "            \n",
    "            \n",
    "#临界值的选取2\n",
    "def AssignBin(x, cutOffPoints,special_attribute=[]):\n",
    "    '''\n",
    "    :param x: the value of variable\n",
    "    :param cutOffPoints: the ChiMerge result for continous variable\n",
    "    :param special_attribute:  the special attribute which should be assigned separately\n",
    "    :return: bin number, indexing from 0\n",
    "    for example, if cutOffPoints = [10,20,30], if x = 7, return Bin 0. If x = 35, return Bin 3\n",
    "    '''\n",
    "    numBin = len(cutOffPoints) + 1 + len(special_attribute)\n",
    "    if x in special_attribute:\n",
    "        i = special_attribute.index(x)+1\n",
    "        return 'Bin {}'.format(0-i)\n",
    "    if x<=cutOffPoints[0]:\n",
    "        return 'Bin 0'\n",
    "    elif x > cutOffPoints[-1]:\n",
    "        return 'Bin {}'.format(numBin-1)\n",
    "    else:\n",
    "        for i in range(0,numBin-1):\n",
    "            if cutOffPoints[i] < x <=  cutOffPoints[i+1]:\n",
    "                return 'Bin {}'.format(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 计算坏样本率\n",
    "def BinBadRate(df, col, target, grantRateIndicator=0):\n",
    "    '''\n",
    "    :param df: 需要计算好坏比率的数据集\n",
    "    :param col: 需要计算好坏比率的特征\n",
    "    :param target: 好坏标签\n",
    "    :param grantRateIndicator: 1返回总体的坏样本率，0不返回\n",
    "    :return: 每箱的坏样本率，以及总体的坏样本率（当grantRateIndicator＝＝1时）\n",
    "    '''\n",
    "    #先计算每个值的出现次数\n",
    "    total = df.groupby([col])[target].count()\n",
    "    #print(\"1\",total)\n",
    "    total = pd.DataFrame({'total': total})\n",
    "    #先计算每个值中1[即坏样本]的出现次数\n",
    "    bad = df.groupby([col])[target].sum()\n",
    "    bad = pd.DataFrame({'bad': bad})\n",
    "    #将每个值的总数和bad样本数合并\n",
    "    regroup = total.merge(bad, left_index=True, right_index=True, how='left')\n",
    "    regroup.reset_index(level=0, inplace=True)\n",
    "    #计算每个值的坏样本率\n",
    "    regroup['bad_rate'] = regroup.apply(lambda x: x.bad * 1.0 / x.total, axis=1)\n",
    "    dicts = dict(zip(regroup[col],regroup['bad_rate']))\n",
    "    if grantRateIndicator==0:\n",
    "        return (dicts, regroup)\n",
    "    N = sum(regroup['total'])\n",
    "    B = sum(regroup['bad'])\n",
    "    overallRate = B * 1.0 / N\n",
    "    return (dicts, regroup, overallRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 计算卡方值\n",
    "def Chi2(df, total_col, bad_col, overallRate):\n",
    "    '''\n",
    "    :param df: 包含全部样本总计与坏样本总计的数据框\n",
    "    :param total_col: 全部样本的个数\n",
    "    :param bad_col: 坏样本的个数\n",
    "    :param overallRate: 全体样本的坏样本占比\n",
    "    :return: 卡方值\n",
    "    '''\n",
    "    df2 = df.copy()\n",
    "    # 期望坏样本个数＝全部样本个数*平均坏样本占比,即计算Eij\n",
    "    df2['expected'] = df[total_col].apply(lambda x: x*overallRate)\n",
    "    combined = zip(df2['expected'], df2[bad_col])\n",
    "    chi = [(i[0]-i[1])**2/i[0] for i in combined]\n",
    "    chi2 = sum(chi)\n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 计算分箱结果\n",
    "### ChiMerge_MaxInterval: split the continuous variable using Chi-square value by specifying the max number of intervals\n",
    "def ChiMerge(df, col, target, max_interval=5,special_attribute=[],minBinPcnt=0):\n",
    "    '''\n",
    "    :param df: 包含目标变量与分箱属性的数据框\n",
    "    :param col: 需要分箱的属性\n",
    "    :param target: 目标变量，取值0或1\n",
    "    :param max_interval: 最大分箱数。如果原始属性的取值个数低于该参数，不执行这段函数\n",
    "    :param special_attribute: 不参与分箱的属性取值\n",
    "    :param minBinPcnt：最小箱的占比，默认为0\n",
    "    :return: 分箱结果\n",
    "    '''\n",
    "    colLevels = sorted(list(set(df[col])))\n",
    "    N_distinct = len(colLevels)\n",
    "    if N_distinct <= max_interval:  #如果原始属性的取值个数低于max_interval，不执行这段函数\n",
    "        print (\"The number of original levels for {} is less than or equal to max intervals\".format(col))\n",
    "        return colLevels[:-1]\n",
    "    else:\n",
    "        if len(special_attribute)>=1:\n",
    "            df1 = df.loc[df[col].isin(special_attribute)]\n",
    "            df2 = df.loc[~df[col].isin(special_attribute)]\n",
    "        else:\n",
    "            df2 = df.copy()\n",
    "        N_distinct = len(list(set(df2[col])))\n",
    "\n",
    "        # 步骤一: 通过col对数据集进行分组，求出每组的总样本数与坏样本数\n",
    "        if N_distinct > 100:\n",
    "            split_x = SplitData(df2, col, 100)\n",
    "            df2['temp'] = df2[col].map(lambda x: AssignGroup(x, split_x))\n",
    "        else:\n",
    "            df2['temp'] = df[col]\n",
    "        # 总体bad rate将被用来计算expected bad count\n",
    "        (binBadRate, regroup, overallRate) = BinBadRate(df2, 'temp', target, grantRateIndicator=1)\n",
    "\n",
    "        # 首先，每个单独的属性值将被分为单独的一组\n",
    "        # 对属性值进行排序，然后两两组别进行合并\n",
    "        colLevels = sorted(list(set(df2['temp'])))\n",
    "        groupIntervals = [[i] for i in colLevels]\n",
    "\n",
    "        # 步骤二：建立循环，不断合并最优的相邻两个组别，直到：\n",
    "        # 1，最终分裂出来的分箱数<＝预设的最大分箱数\n",
    "        # 2，每箱的占比不低于预设值（可选）\n",
    "        # 3，每箱同时包含好坏样本\n",
    "        # 如果有特殊属性，那么最终分裂出来的分箱数＝预设的最大分箱数－特殊属性的个数\n",
    "        split_intervals = max_interval - len(special_attribute)\n",
    "        while (len(groupIntervals) > split_intervals):  # 终止条件: 当前分箱数＝预设的分箱数\n",
    "            # 每次循环时, 计算合并相邻组别后的卡方值。具有最小卡方值的合并方案，是最优方案\n",
    "            chisqList = []\n",
    "            for k in range(len(groupIntervals)-1):\n",
    "                temp_group = groupIntervals[k] + groupIntervals[k+1]\n",
    "                df2b = regroup.loc[regroup['temp'].isin(temp_group)]\n",
    "                chisq = Chi2(df2b, 'total', 'bad', overallRate)\n",
    "                chisqList.append(chisq)\n",
    "            best_comnbined = chisqList.index(min(chisqList))\n",
    "            groupIntervals[best_comnbined] = groupIntervals[best_comnbined] + groupIntervals[best_comnbined+1]\n",
    "            # after combining two intervals, we need to remove one of them\n",
    "            groupIntervals.remove(groupIntervals[best_comnbined])\n",
    "        groupIntervals = [sorted(i) for i in groupIntervals]\n",
    "        #print(groupIntervals)\n",
    "        cutOffPoints = [max(i) for i in groupIntervals[:-1]]\n",
    "        \n",
    "    \n",
    "        # 检查是否有箱没有好或者坏样本。如果有，需要跟相邻的箱进行合并，直到每箱同时包含好坏样本\n",
    "        groupedvalues = df2['temp'].apply(lambda x: AssignBin(x, cutOffPoints))\n",
    "        df2['temp_Bin'] = groupedvalues\n",
    "        (binBadRate,regroup) = BinBadRate(df2, 'temp_Bin', target)\n",
    "        [minBadRate, maxBadRate] = [min(binBadRate.values()),max(binBadRate.values())]\n",
    "        while minBadRate ==0 or maxBadRate == 1:\n",
    "            # 找出全部为好／坏样本的箱\n",
    "            indexForBad01 = regroup[regroup['bad_rate'].isin([0,1])].temp_Bin.tolist()\n",
    "            bin=indexForBad01[0]\n",
    "            # 如果是最后一箱，则需要和上一个箱进行合并，也就意味着分裂点cutOffPoints中的最后一个需要移除\n",
    "            if bin == max(regroup.temp_Bin):\n",
    "                cutOffPoints = cutOffPoints[:-1]\n",
    "            # 如果是第一箱，则需要和下一个箱进行合并，也就意味着分裂点cutOffPoints中的第一个需要移除\n",
    "            elif bin == min(regroup.temp_Bin):\n",
    "                cutOffPoints = cutOffPoints[1:]\n",
    "            # 如果是中间的某一箱，则需要和前后中的一个箱进行合并，依据是较小的卡方值\n",
    "            else:\n",
    "                # 和前一箱进行合并，并且计算卡方值\n",
    "                currentIndex = list(regroup.temp_Bin).index(bin)\n",
    "                prevIndex = list(regroup.temp_Bin)[currentIndex - 1]\n",
    "                df3 = df2.loc[df2['temp_Bin'].isin([prevIndex, bin])]\n",
    "                (binBadRate, df2b) = BinBadRate(df3, 'temp_Bin', target)\n",
    "                chisq1 = Chi2(df2b, 'total', 'bad', overallRate)\n",
    "                # 和后一箱进行合并，并且计算卡方值\n",
    "                laterIndex = list(regroup.temp_Bin)[currentIndex + 1]\n",
    "                df3b = df2.loc[df2['temp_Bin'].isin([laterIndex, bin])]\n",
    "                (binBadRate, df2b) = BinBadRate(df3b, 'temp_Bin', target)\n",
    "                chisq2 = Chi2(df2b, 'total', 'bad', overallRate)\n",
    "                if chisq1 < chisq2:\n",
    "                    cutOffPoints.remove(cutOffPoints[currentIndex - 1])\n",
    "                else:\n",
    "                    cutOffPoints.remove(cutOffPoints[currentIndex])\n",
    "            # 完成合并之后，需要再次计算新的分箱准则下，每箱是否同时包含好坏样本\n",
    "            groupedvalues = df2['temp'].apply(lambda x: AssignBin(x, cutOffPoints))\n",
    "            df2['temp_Bin'] = groupedvalues\n",
    "            (binBadRate, regroup) = BinBadRate(df2, 'temp_Bin', target)\n",
    "            [minBadRate, maxBadRate] = [min(binBadRate.values()), max(binBadRate.values())]\n",
    "        # 需要检查分箱后的最小占比\n",
    "        if minBinPcnt > 0:\n",
    "            groupedvalues = df2['temp'].apply(lambda x: AssignBin(x, cutOffPoints))\n",
    "            df2['temp_Bin'] = groupedvalues\n",
    "            valueCounts = groupedvalues.value_counts().to_frame()\n",
    "            valueCounts['pcnt'] = valueCounts['temp'].apply(lambda x: x * 1.0 / N)\n",
    "            valueCounts = valueCounts.sort_index()\n",
    "            minPcnt = min(valueCounts['pcnt'])\n",
    "            while minPcnt < 0.05 and len(cutOffPoints) > 2:\n",
    "                # 找出占比最小的箱\n",
    "                indexForMinPcnt = valueCounts[valueCounts['pcnt'] == minPcnt].index.tolist()[0]\n",
    "                # 如果占比最小的箱是最后一箱，则需要和上一个箱进行合并，也就意味着分裂点cutOffPoints中的最后一个需要移除\n",
    "                if indexForMinPcnt == max(valueCounts.index):\n",
    "                    cutOffPoints = cutOffPoints[:-1]\n",
    "                # 如果占比最小的箱是第一箱，则需要和下一个箱进行合并，也就意味着分裂点cutOffPoints中的第一个需要移除\n",
    "                elif indexForMinPcnt == min(valueCounts.index):\n",
    "                    cutOffPoints = cutOffPoints[1:]\n",
    "                # 如果占比最小的箱是中间的某一箱，则需要和前后中的一个箱进行合并，依据是较小的卡方值\n",
    "                else:\n",
    "                    # 和前一箱进行合并，并且计算卡方值\n",
    "                    currentIndex = list(valueCounts.index).index(indexForMinPcnt)\n",
    "                    prevIndex = list(valueCounts.index)[currentIndex - 1]\n",
    "                    df3 = df2.loc[df2['temp_Bin'].isin([prevIndex, indexForMinPcnt])]\n",
    "                    (binBadRate, df2b) = BinBadRate(df3, 'temp_Bin', target)\n",
    "                    chisq1 = Chi2(df2b, 'total', 'bad', overallRate)\n",
    "                    # 和后一箱进行合并，并且计算卡方值\n",
    "                    laterIndex = list(valueCounts.index)[currentIndex + 1]\n",
    "                    df3b = df2.loc[df2['temp_Bin'].isin([laterIndex, indexForMinPcnt])]\n",
    "                    (binBadRate, df2b) = BinBadRate(df3b, 'temp_Bin', target)\n",
    "                    chisq2 = Chi2(df2b, 'total', 'bad', overallRate)\n",
    "                    if chisq1 < chisq2:\n",
    "                        cutOffPoints.remove(cutOffPoints[currentIndex - 1])\n",
    "                    else:\n",
    "                        cutOffPoints.remove(cutOffPoints[currentIndex])\n",
    "        cutOffPoints = special_attribute + cutOffPoints\n",
    "        return cutOffPoints    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.检查单调性\n",
    "def BadRateMonotone(df, sortByVar, target,special_attribute = []):\n",
    "    '''\n",
    "    :param df: the dataset contains the column which should be monotone with the bad rate and bad column\n",
    "    :param sortByVar: the column which should be monotone with the bad rate\n",
    "    :param target: the bad column\n",
    "    :param special_attribute: some attributes should be excluded when checking monotone\n",
    "    :return:\n",
    "    '''\n",
    "    df2 = df.loc[~df[sortByVar].isin(special_attribute)]\n",
    "    if len(set(df2[sortByVar])) <= 2:\n",
    "        return True\n",
    "    regroup = BinBadRate(df2, sortByVar, target)[1]\n",
    "    print(\"regroup:\",regroup)\n",
    "    combined = zip(regroup['total'],regroup['bad'])\n",
    "    print(\"combined:\",combined)\n",
    "    badRate = [x[1]*1.0/x[0] for x in combined]\n",
    "    print(\"badRate:\",badRate)\n",
    "    #优先级关系：or<and<not\n",
    "    badRateMonotone = [badRate[i]<badRate[i+1] \n",
    "                       for i in range(0,len(badRate)-1)]\n",
    "    print(\"badRateMonotone:\",badRateMonotone)\n",
    "    #set去重，如果全部为False/True则单调，否则不单调\n",
    "    Monotone = len(set(badRateMonotone))\n",
    "    if Monotone == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只选取一个字段进行测试\n",
    "num_features=[\"annual_inc\"]\n",
    "#设置目标变量\n",
    "target='y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_inc is in processing\n",
      "398\n",
      "[[14400.0], [35142.0], [36000.0], [39192.0], [100000000000.0]]\n",
      "regroup:   annual_inc_Bin  total   bad  bad_rate\n",
      "0          Bin 0    423   104  0.245863\n",
      "1          Bin 1   6344  1097  0.172919\n",
      "2          Bin 2    736   149  0.202446\n",
      "3          Bin 3   1254   215  0.171451\n",
      "4          Bin 4  31028  4105  0.132300\n",
      "combined: <zip object at 0x11718c8c8>\n",
      "badRate: [0.2458628841607565, 0.17291929382093316, 0.20244565217391305, 0.17145135566188197, 0.13229985819260023]\n",
      "badRateMonotone: [False, True, False, False]\n",
      "398\n",
      "[[14400.0], [35142.0], [36000.0], [100000000000.0]]\n",
      "regroup:   annual_inc_Bin  total   bad  bad_rate\n",
      "0          Bin 0    423   104  0.245863\n",
      "1          Bin 1   6344  1097  0.172919\n",
      "2          Bin 2    736   149  0.202446\n",
      "3          Bin 3  32282  4320  0.133821\n",
      "combined: <zip object at 0x1171d4548>\n",
      "badRate: [0.2458628841607565, 0.17291929382093316, 0.20244565217391305, 0.13382070503686264]\n",
      "badRateMonotone: [False, True, False]\n",
      "398\n",
      "[[14400.0], [36000.0], [100000000000.0]]\n",
      "regroup:   annual_inc_Bin  total   bad  bad_rate\n",
      "0          Bin 0    423   104  0.245863\n",
      "1          Bin 1   7080  1246  0.175989\n",
      "2          Bin 2  32282  4320  0.133821\n",
      "combined: <zip object at 0x117111b48>\n",
      "badRate: [0.2458628841607565, 0.17598870056497176, 0.13382070503686264]\n",
      "badRateMonotone: [False, False]\n"
     ]
    }
   ],
   "source": [
    "#对所有需要分箱的变量\n",
    "for col in num_features:\n",
    "    print (\"{} is in processing\".format(col))\n",
    "    #对于特殊值的处理，是否存在特殊值，比如[-1]\n",
    "    if -1 not in set(data[col]):\n",
    "        max_interval = 5\n",
    "        cutOff = ChiMerge(data, col, target, max_interval=max_interval,special_attribute=[],minBinPcnt=0)\n",
    "        data[col+'_Bin'] = data[col].map(lambda x: AssignBin(x, cutOff,special_attribute=[]))\n",
    "        monotone = BadRateMonotone(data, col+'_Bin', 'y')\n",
    "        while(not monotone):\n",
    "            #如果不单调，最大分箱数减一，重新分箱\n",
    "            max_interval -= 1\n",
    "            cutOff = ChiMerge(data, col, target, max_interval=max_interval, special_attribute=[],\n",
    "                                          minBinPcnt=0)\n",
    "            data[col + '_Bin'] = data[col].map(lambda x: AssignBin(x, cutOff, special_attribute=[]))\n",
    "            if max_interval == 2:\n",
    "                # 当分箱数为2时，必然单调\n",
    "                break\n",
    "            monotone = BadRateMonotone(data, col + '_Bin', 'y')\n",
    "    else:\n",
    "        max_interval = 5\n",
    "        cutOff = ChiMerge(data, col, target, max_interval=max_interval, special_attribute=[-1],\n",
    "                                      minBinPcnt=0)\n",
    "        data[col + '_Bin'] = data[col].map(lambda x: AssignBin(x, cutOff, special_attribute=[-1]))\n",
    "        monotone = BadRateMonotone(data, col + '_Bin', 'y')\n",
    "        while (not monotone):\n",
    "            max_interval -= 1\n",
    "            cutOff = ChiMerge(data, col, target, max_interval=max_interval, special_attribute=[-1],\n",
    "                                          minBinPcnt=0)\n",
    "            data[col + '_Bin'] = data[col].map(lambda x: AssignBin(x, cutOff, special_attribute=[-1]))\n",
    "            if max_interval == 2:\n",
    "                # 当分箱数为2时，必然单调\n",
    "                break\n",
    "            monotone = BadRateMonotone(data, col + '_Bin', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
